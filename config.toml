[base]
policy_name = "Policy"
# rnn_name = None  # Assign a value when needed.

[env]

[policy]

[rnn]

[train]
seed = 1
torch_deterministic = true
cpu_offload = false
device = "cuda"
total_timesteps = 10_000_000
learning_rate = 2.5e-4
anneal_lr = true
gamma = 0.99
gae_lambda = 0.95
update_epochs = 4
norm_adv = true
clip_coef = 0.1
clip_vloss = true
vf_coef = 0.5
vf_clip_coef = 0.1
max_grad_norm = 0.5
ent_coef = 0.01
# target_kl = None  # Assign a value when needed.

num_envs = 8
num_workers = 8
env_batch_size = 8
zero_copy = true
data_dir = "experiments"
checkpoint_interval = 200
batch_size = 1024
minibatch_size = 512
bptt_horizon = 16
compile = false
compile_mode = "reduce-overhead"
